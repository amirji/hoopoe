{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd600bed",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f09bd2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pdftotext\n",
    "from PyPDF2 import PdfFileReader\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1cde8ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(folder_name):\n",
    "    \"\"\"\n",
    "    This function assumes that the folder \"folder_name\" is stored inside the the notebooks folder.\n",
    "    Params:\n",
    "    folder_name: string\n",
    "    Returns: the paths to the data files in the given folder as a list.\n",
    "    \"\"\"\n",
    "    arr = os.listdir(folder_name)\n",
    "    return [os.path.join(os.getcwd(),folder_name, a) for a in arr]\n",
    "\n",
    "\n",
    "def pdftotext_wrapper(input_file, options=None, output_file=None):\n",
    "    \"\"\"\n",
    "    This function wraps the pdftotext command line tool.\n",
    "    Params:\n",
    "    input_file: string of path to the input pdf file.\n",
    "    output_file: string of path to the output text file.\n",
    "    options: string\n",
    "    Returns: the text as a string.\n",
    "    \"\"\"\n",
    "    if options is None:\n",
    "        options = \"\"\n",
    "\n",
    "    if output_file is None:\n",
    "        output_file = \"\"\n",
    "\n",
    "    check = os.popen(\"pdftotext \" + options + \" \" + input_file + \" \" + output_file).read()\n",
    "    if check == \"\":\n",
    "        return \"Success\"\n",
    "\n",
    "\n",
    "def extract_text(path, method):\n",
    "    \"\"\"\n",
    "    This function extracts the text from a pdf file.\n",
    "    Params:\n",
    "    path: string\n",
    "    method: string\n",
    "    Returns: the text as a string.\n",
    "    \"\"\"\n",
    "    if method == \"pdftotext_cli\":\n",
    "        file_name = path.replace(os.path.dirname(data[0])+\"/\", \"\").replace(\".pdf\", \"\")\n",
    "        output_dir = os.path.join(os.getcwd(), \"texts\")\n",
    "        output_file = os.path.join(output_dir, file_name + \".txt\")\n",
    "        pdftotext_wrapper(data[0], \"-raw\", output_file) \n",
    "        with open(output_file, 'r') as f:\n",
    "            #return f.read()\n",
    "            return f.read().replace(\"\\n\", \" \")\n",
    "            #return f.readlines()\n",
    "\n",
    "    if method == \"pdftotext_python\":\n",
    "        with open(path, \"rb\") as f:\n",
    "            return pdftotext.PDF(f)\n",
    "\n",
    "    if method == \"pypdf2\":\n",
    "        text = []\n",
    "        with open(path, \"rb\") as f:\n",
    "            pdf = PdfFileReader(f)\n",
    "            text = [pdf.getPage(i).extractText() for i in range(pdf.numPages)]\n",
    "            return text\n",
    "\n",
    "def extract_entities(quote):\n",
    "    words = word_tokenize(quote)\n",
    "    tags = nltk.pos_tag(words)\n",
    "    tree = nltk.ne_chunk(tags, binary=True)\n",
    "    return set(\n",
    "        \" \".join(i[0] for i in t)\n",
    "        for t in tree\n",
    "        if hasattr(t, \"label\") and t.label() == \"NE\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3943b35",
   "metadata": {},
   "source": [
    "### Pipline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5608f9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(\"pdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ff07fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = extract_text(data[0], \"pdftotext_cli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "edc6d444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A1',\n",
       " 'A2',\n",
       " 'AM',\n",
       " 'AN',\n",
       " 'AND',\n",
       " 'AXy',\n",
       " 'Abelian',\n",
       " 'Ac',\n",
       " 'AihG',\n",
       " 'Alexander',\n",
       " 'Am Neuen Palais',\n",
       " 'Austria',\n",
       " 'Austrian',\n",
       " 'Ax',\n",
       " 'B',\n",
       " 'B1',\n",
       " 'B2',\n",
       " 'Barnum',\n",
       " 'Bell',\n",
       " 'Bennett',\n",
       " 'Binary',\n",
       " 'Bipolar Sequences',\n",
       " 'Blackett Laboratory',\n",
       " 'Boltzmann',\n",
       " 'Briegel',\n",
       " 'Browne',\n",
       " 'CSS',\n",
       " 'CalTech',\n",
       " 'Cambridge',\n",
       " 'Cambridge University Press',\n",
       " 'Cartesian',\n",
       " 'Chuang',\n",
       " 'Cirac',\n",
       " 'Clifford',\n",
       " 'Combinatorics',\n",
       " 'DEGREE OF',\n",
       " 'DISCUSSION',\n",
       " 'De Moor',\n",
       " 'Deutsche Forschungsgemeinschaft',\n",
       " 'Discrete Math',\n",
       " 'Discrete Mathematics',\n",
       " 'E',\n",
       " 'EAB',\n",
       " 'ES',\n",
       " 'ESAT',\n",
       " 'EVALUATION OF',\n",
       " 'Ed',\n",
       " 'Eisert',\n",
       " 'Electr',\n",
       " 'Electrical Engineering',\n",
       " 'Electronic Journal',\n",
       " 'Eq',\n",
       " 'European Commission',\n",
       " 'European Science Foundation',\n",
       " 'FIG',\n",
       " 'Feodor Lynen Grant',\n",
       " 'Fig',\n",
       " 'Figs',\n",
       " 'G',\n",
       " 'G1',\n",
       " 'G2',\n",
       " 'G4',\n",
       " 'GAAc',\n",
       " 'GAB',\n",
       " 'GENERAL',\n",
       " 'GF',\n",
       " 'GRAPH',\n",
       " 'GRAPHS',\n",
       " 'Gardiner',\n",
       " 'Geremia',\n",
       " 'Germany',\n",
       " 'Glynn',\n",
       " 'Graph',\n",
       " 'Graph No',\n",
       " 'Graph Theory',\n",
       " 'Graphs',\n",
       " 'Group Theoretical Methods',\n",
       " 'H',\n",
       " 'HV',\n",
       " 'Heidelberg',\n",
       " 'Heisenberg',\n",
       " 'Hence',\n",
       " 'Hermitian',\n",
       " 'Hilbert',\n",
       " 'IEEE International Symposium',\n",
       " 'III',\n",
       " 'III B',\n",
       " 'III E',\n",
       " 'IIIB',\n",
       " 'Imperial College London',\n",
       " 'International Press',\n",
       " 'Introduction',\n",
       " 'J. Calsamiglia',\n",
       " 'J. Dehaene',\n",
       " 'J. Eisert',\n",
       " 'J. Eisert3,4',\n",
       " 'J. Kundu',\n",
       " 'J. Phys',\n",
       " 'Jacobs',\n",
       " 'K',\n",
       " 'L',\n",
       " 'LOCC',\n",
       " 'LU',\n",
       " 'Laplacian',\n",
       " 'Latorre',\n",
       " 'Lausanne',\n",
       " 'Lett',\n",
       " 'Leuven',\n",
       " 'Linden',\n",
       " 'Local',\n",
       " 'Local Pauli',\n",
       " 'London',\n",
       " 'Lukin',\n",
       " 'MA',\n",
       " 'MREGS',\n",
       " 'Maks',\n",
       " 'Math',\n",
       " 'Mathematische Annalen',\n",
       " 'Maximal Schmidt',\n",
       " 'Maxwell',\n",
       " 'Na',\n",
       " 'Na1',\n",
       " 'Na2',\n",
       " 'Na3',\n",
       " 'Nature',\n",
       " 'Nb0',\n",
       " 'Nest',\n",
       " 'Nielsen',\n",
       " 'No',\n",
       " 'Note',\n",
       " 'Osterloh',\n",
       " 'Otherwise',\n",
       " 'P',\n",
       " 'PACS',\n",
       " 'Parker',\n",
       " 'Pasadena',\n",
       " 'Pauli',\n",
       " 'Petersen',\n",
       " 'PhD',\n",
       " 'Phys',\n",
       " 'Physics',\n",
       " 'Physik',\n",
       " 'Plenio',\n",
       " 'Potsdam',\n",
       " 'Preprint',\n",
       " 'Prince Consort Road',\n",
       " 'Proc',\n",
       " 'Px',\n",
       " 'Py',\n",
       " 'Pz',\n",
       " 'QFT',\n",
       " 'Quadratic Forms',\n",
       " 'Quant',\n",
       " 'Quantum Codes',\n",
       " 'Quantum Computation',\n",
       " 'Quantum Computers',\n",
       " 'Quantum Entanglement',\n",
       " 'Quantum Error',\n",
       " 'Quantum Fourier Transform',\n",
       " 'Quantum Fourier Transformation',\n",
       " 'Quantum Inf',\n",
       " 'Quantum Information',\n",
       " 'Quantum Optics',\n",
       " 'R',\n",
       " 'RI2',\n",
       " 'RI3',\n",
       " 'Ref',\n",
       " 'Refs',\n",
       " 'Rico',\n",
       " 'SCHMIDT',\n",
       " 'SETA',\n",
       " 'SG',\n",
       " 'SLOCC',\n",
       " 'SN',\n",
       " 'Schlingemann',\n",
       " 'Schmidt',\n",
       " 'Schwerpunkt',\n",
       " 'Sciences',\n",
       " 'Sec',\n",
       " 'Sequences',\n",
       " 'Signal Processing',\n",
       " 'Smolin',\n",
       " 'Springer',\n",
       " 'Stabilizer Codes',\n",
       " 'Stockton',\n",
       " 'Switzerland',\n",
       " 'TABLE',\n",
       " 'THE',\n",
       " 'Table',\n",
       " 'Table II',\n",
       " 'Thapliyal',\n",
       " 'U',\n",
       " 'U K',\n",
       " 'UK',\n",
       " 'Ua',\n",
       " 'Upper',\n",
       " 'Upper Saddle River',\n",
       " 'V',\n",
       " 'Van',\n",
       " 'Vertex',\n",
       " 'Virmani',\n",
       " 'Werner',\n",
       " 'West',\n",
       " 'Westmoreland',\n",
       " 'Wolf',\n",
       " 'X',\n",
       " 'XXII International',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'Zhang',\n",
       " 'Zoller',\n",
       " 'arXiv',\n",
       " 'hUK',\n",
       " 'rankF2',\n",
       " 'trA',\n",
       " 'ΓAB',\n",
       " 'ΓG',\n",
       " 'ΓGAB',\n",
       " 'σxPz'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_entities(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ec68ae4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sent_tokenize() got an unexpected keyword argument 'preserve_line'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_584765/228008649.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sent_tokenize() got an unexpected keyword argument 'preserve_line'"
     ]
    }
   ],
   "source": [
    "tt = sent_tokenize(t, language='english', preserve_line=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3830a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(tt[10])\n",
    "tags = nltk.pos_tag(words)\n",
    "tree = nltk.ne_chunk(tags, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2830d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "557dffe6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_584765/1253030878.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/nltk/chunk/__init__.py\u001b[0m in \u001b[0;36mne_chunk\u001b[0;34m(tagged_tokens, binary)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mchunker_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_MULTICLASS_NE_CHUNKER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mchunker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunker_pickle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/nltk/chunk/named_entity.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mEach\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtagged\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \"\"\"\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mtagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tagged_to_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/nltk/tag/sequential.py\u001b[0m in \u001b[0;36mtag\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/nltk/tag/sequential.py\u001b[0m in \u001b[0;36mtag_one\u001b[0;34m(self, tokens, index, history)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtagger\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_taggers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/nltk/tag/sequential.py\u001b[0m in \u001b[0;36mchoose_tag\u001b[0;34m(self, tokens, index, history)\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchoose_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;31m# Use our feature detector to get the featureset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0mfeatureset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;31m# Use the classifier to pick a tag.  If a cutoff probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/nltk/tag/sequential.py\u001b[0m in \u001b[0;36mfeature_detector\u001b[0;34m(self, tokens, index, history)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0mSee\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \"\"\"\n\u001b[0;32m--> 694\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/nltk/chunk/named_entity.py\u001b[0m in \u001b[0;36m_feature_detector\u001b[0;34m(self, tokens, index, history)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_feature_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimplify_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mprevword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevprevword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "print(nltk.ne_chunk(tt[10], binary=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hoopoe",
   "language": "python",
   "name": "hoopoe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
